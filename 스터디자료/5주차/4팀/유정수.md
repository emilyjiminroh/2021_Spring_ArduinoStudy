5주차 시작!!!(Teachable Machine)
===========
시작하는 말
-----------
드디어 2차 인증 시험이 끝났다.....교수님이 쉽게 낸다면서 다 어렵게 나와서                   
단단히 털렸다...ㅠㅠㅠ(한강 가즈아!!!)          이번주 다른 공부 버리고 C만 공부했는데 결과가 이 모양이니......
(재수강 무야호!!!)

Teachable Machine이란?
---------
Teachable Machine은 구글에서 만든 툴로 인공지능을 쉽게 만들 수 있는 툴이다.                
진짜 사용법이 쉬워서 구글에서는 6살 아이한테 인공지능을 가르칠 때 이 툴을 사용한다고 한다(ㅎㄷㄷ....)                    
(사실 필자는 고등학교 때 학생부 준비하면서 한 번 만져봤다 ㅋㅋㅋ, 그래서 스마클에서 Teachable Machine도 다룬다는 거 듣고 엄청 기뻤다 ㅋㅋㅋ) 

 인공지능을 만들어보자!!!
 ===========
 주제 선정
 ----------
 뭘 구분하는 인공지능을 만들어볼까?           고민하다 필자가 선택한 건 필자가 제일 좋아하는 격투게임인 '슈퍼 스매시 브라더스'에 나오는 파이터들을 구분하는 모델을 만들어보는 것이다.
 (파이터들이 너무 많아서 몇 명만 선정해서 만들었다.)
 ![Document](https://user-images.githubusercontent.com/81175672/119004373-75bfc800-b9c9-11eb-9c09-412a1ca80a43.jpg)
 
 학습 데이터 입력
 --------
![KakaoTalk_20210408_224839360](https://user-images.githubusercontent.com/81175672/119004712-c0d9db00-b9c9-11eb-9a7d-cc90d27e5a24.jpg)                      
위 사진처럼 학습시킬 사진이나 영상만 드래그해서 옮기면 학습 데이터 입력이 된다....엄청 쉽다....

![mario](https://user-images.githubusercontent.com/81175672/119004919-f088e300-b9c9-11eb-8d98-81b1cb9f9bb9.JPG)                  
학습 데이터의 첫 타자는 바로 영원한 닌텐도의 마스코트 마리오!!!                     
(최근에 USJ에 닌텐도 월드 생겼다는데 가고 싶다.....근데 코로나....)

![sonic](https://user-images.githubusercontent.com/81175672/119005134-27f78f80-b9ca-11eb-8c5b-508654c22b70.JPG)                       
다음은 마리오의 라이벌이자 SEGA의 마스코드 소닉!!                     
(올해로 뭐 30주년이라는데 게임을 다 망쳐서 뭐...고닉...)

![link](https://user-images.githubusercontent.com/81175672/119005700-a5bb9b00-b9ca-11eb-88b8-8ca5b338866f.JPG)                      
매번 젤다로 착각하는 링크!!                   
(여담으로 링크는 컴퓨터 용어 하이퍼 링크에서 가져왔다고 한다....)

![zelda](https://user-images.githubusercontent.com/81175672/119006242-27abc400-b9cb-11eb-967d-f15e3503d9c7.JPG)                
젤다의 전설의 진짜 주인공? 젤다!!

![shulk](https://user-images.githubusercontent.com/81175672/119006400-4c07a080-b9cb-11eb-8cf4-a9615f86ecb9.JPG)                 
다음은 필자가 제일 좋아하는 닌텐도 캐릭터 슈르크!!!

![pit](https://user-images.githubusercontent.com/81175672/119006492-6477bb00-b9cb-11eb-9f76-7aa0f18dbc59.JPG)                  
키드 이카루스의 피트!!!                      
(여담으로 성우가 코난 성우...ㅋ)

![pikachu](https://user-images.githubusercontent.com/81175672/119006754-98eb7700-b9cb-11eb-8d3d-8b928420549c.JPG)                    
포켓몬의 영원한 마스코트 피카츄!!!                  
(피카츄, 라이츄, 파이리, 꼬부기~우리는 모두 친구)

![kirby](https://user-images.githubusercontent.com/81175672/119006909-bf111700-b9cb-11eb-9ebb-7a59167b0b4d.JPG)                      
닌텐도의 분홍색 찐빵 커비!!

![meta knight](https://user-images.githubusercontent.com/81175672/119006972-cf28f680-b9cb-11eb-92a4-e21ed16c4039.JPG)                    
가면만 벗으면 파란 커비인 메타 나이트 !!

![cloud](https://user-images.githubusercontent.com/81175672/119007255-0697a300-b9cc-11eb-83ca-8ef5c72be36d.JPG)                     
JRPG의 대명사 FINAL FANTASY VII에 나오는 클라우드!!                           
(최근에 리메이크되었죠!!!...근데 ps4가 없다....ㅠㅠ)                      

모델 만들기
--------
![train](https://user-images.githubusercontent.com/81175672/119008047-c2f16900-b9cc-11eb-8621-26531d5353ce.JPG)                         
Train Model을 누르면 자동으로 학습 모델이 만들어진다.


![ki](https://user-images.githubusercontent.com/81175672/119007867-976e7e80-b9cc-11eb-9c81-0fcf072076d7.JPG)            
파란 창에 사진을 입력하면 학습 모델과 비교해서 비슷한 정도를 수치로 보여준다.

모델을 작동시켜보자
---------
![커비 시도](https://user-images.githubusercontent.com/81175672/119008487-2e3b3b00-b9cd-11eb-8f9d-c73965f5d53c.JPG)                           
학습 모델을 만들 때 사용한 커비 사진을 넣으니 높은 확률로 커비랑 비슷하다고 나온다.
![mario kirby](https://user-images.githubusercontent.com/81175672/119008641-532fae00-b9cd-11eb-9bbd-e96ef9453157.JPG)                  
마리오 커비 사진을 넣어보니 아까보다는 확률이 아주 조금 떨어졌지만 커비랑 비슷하다고 나온다.
![마이크 커비](https://user-images.githubusercontent.com/81175672/119008805-72c6d680-b9cd-11eb-9227-3af1fe889105.JPG)
마이크 커비 사진도 확률은 좀 떨어졌지만 커비랑 비슷하다고 나온다.

epoch란?
----------
이번 서브 미션인 epoch에 대해 알아보자.            
한 번의 epoch는 인공 신경망에서 전체 데이터 셋에 대해 forward pass/backward pass 과정을 거친 것을 말한다.                 
즉, 전체 데이터 셋에 대해 한 번 학습을 완료한 상태를 의미한다.
(출처: https://m.blog.naver.com/qbxlvnf11/221449297033)

![ki](https://user-images.githubusercontent.com/81175672/119007867-976e7e80-b9cc-11eb-9c81-0fcf072076d7.JPG)                    
예를 들어 위 사진처럼 epoch가 50이라는 것은 입력한 전체 데이터를 이 모델이 50번 학습했다는 뜻이다.            

epoch를 바꿔서 모델을 만들어보자
----------
기존의 학습 데이터로 epoch를 58로 설정하고 모델을 다시 만들어보았다.                     
(처음꺼는 epoch가 50)                          

![epochs2](https://user-images.githubusercontent.com/81175672/119009837-7c047300-b9ce-11eb-9d31-df7f516f1e97.JPG)            
방금 전 마이크 커비 사진을 다시 넣어보니 여전히 커비라고 높은 확률로 나오지만 이전 꺼랑은 다르게 마리오랑 비슷한 확률이 올라갔다.


즉, 이전 모델과는 다르게 민감도가 높아진 것을 확인할 수 있다.                 
(복습을 많이 하면 기억나는 내용이 많아지는 것처럼 말이다..)

마무리
========
Teachable Machine을 다시 만져보니 이렇게나 쉬운 툴을 만든 구글이 참 대단하다는 생각을 다시 하게 되었다.ㅋㅋ         
앞으로는 코딩 뿐만 아니라 인공지능도 쉽게 배울 날이 다가올 것 같다고 느낀다.....

만든 학습 모델 코드
---------

```html
<div>Teachable Machine Image Model</div>
<button type="button" onclick="init()">Start</button>
<div id="webcam-container"></div>
<div id="label-container"></div>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
<script type="text/javascript">
    // More API functions here:
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

    // the link to your model provided by Teachable Machine export panel
    const URL = "{{URL}}";

    let model, webcam, labelContainer, maxPredictions;

    // Load the image model and setup the webcam
    async function init() {
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const flip = true; // whether to flip the webcam
        webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
        await webcam.setup(); // request access to the webcam
        await webcam.play();
        window.requestAnimationFrame(loop);

        // append elements to the DOM
        document.getElementById("webcam-container").appendChild(webcam.canvas);
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < maxPredictions; i++) { // and class labels
            labelContainer.appendChild(document.createElement("div"));
        }
    }

    async function loop() {
        webcam.update(); // update the webcam frame
        await predict();
        window.requestAnimationFrame(loop);
    }

    // run the webcam image through the image model
    async function predict() {
        // predict can take in an image, video or canvas html element
        const prediction = await model.predict(webcam.canvas);
        for (let i = 0; i < maxPredictions; i++) {
            const classPrediction =
                prediction[i].className + ": " + prediction[i].probability.toFixed(2);
            labelContainer.childNodes[i].innerHTML = classPrediction;
        }
    }
</script>
```
