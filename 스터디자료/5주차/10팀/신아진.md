5주차 미션 : 티쳐블머신으로 자기만의 인공지능 분류모델 1개 만들기
======
1. 티쳐블머신 사이트 탐방
------
![image](https://user-images.githubusercontent.com/81348844/119147164-4c18a680-ba86-11eb-9551-ca079dacfedf.png)
   
   공지에 걸어주신 티쳐블머신 사이트 링크를 타고 들어갔다.   
   강의와 함께 들으며 사이트를 탐방했는데   
   우리가 만들 수 있는 분류모델의 종류는 '이미지 분류' , '음성 분류', '동작 분류' 3가지 였다.   
   그중에서 나는 쉽게 만들 수 있는 이미지로 분류하기를 택했다. 키득키득   

------ 
2. 나만의 인공지능 분류모델 만들기 : '햄스터 종류 분류 모델'
------
   요즘 유튜브에서 햄스터 영상 보는 것에 푹 빠졌다.   
   나는 햄스터를 초등학교때부터 좋아했었는데 ( 실제로도 약 5년간  길러봄 ) 햄스터 영상이 유튜브 알고리즘에 의해 자꾸 뜨게되어 계속 보게 되는 것 같다.   
   구글링으로 햄스터 종류별로 사진을 각각 10개씩 모아 각 class별 이미지로 추가했다.   
   강의에서도 다각도의 사진들을 모으길래 나도 최대한 햄스터들의 다각도 사진 ( 햄스터 궁딩이 마저도 수집 ,,, ) 을 모으려고 노력했다.   
   '펄 햄스터', '정글리안 햄스터', '푸딩 햄스터'의 사진들을 모으는 과정은 너무나도 행복했다. ( 귀여워서,,,,,,, )   
   
   ![image](https://user-images.githubusercontent.com/81348844/119148100-263fd180-ba87-11eb-8b65-388fc724b513.png)   
   기본 세팅은 건드리지 않고 일단 분류 모델을 만들었다.   
   홈페이지에서 복사한 코드는 아래와 같다.   
   
   <div>Teachable Machine Image Model</div>
<button type="button" onclick="init()">Start</button>
<div id="webcam-container"></div>
<div id="label-container"></div>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
<script type="text/javascript">
    // More API functions here:
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

    // the link to your model provided by Teachable Machine export panel
    const URL = "./my_model/";

    let model, webcam, labelContainer, maxPredictions;

    // Load the image model and setup the webcam
    async function init() {
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const flip = true; // whether to flip the webcam
        webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
        await webcam.setup(); // request access to the webcam
        await webcam.play();
        window.requestAnimationFrame(loop);

        // append elements to the DOM
        document.getElementById("webcam-container").appendChild(webcam.canvas);
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < maxPredictions; i++) { // and class labels
            labelContainer.appendChild(document.createElement("div"));
        }
    }

    async function loop() {
        webcam.update(); // update the webcam frame
        await predict();
        window.requestAnimationFrame(loop);
    }

    // run the webcam image through the image model
    async function predict() {
        // predict can take in an image, video or canvas html element
        const prediction = await model.predict(webcam.canvas);
        for (let i = 0; i < maxPredictions; i++) {
            const classPrediction =
                prediction[i].className + ": " + prediction[i].probability.toFixed(2);
            labelContainer.childNodes[i].innerHTML = classPrediction;
        }
    }
</script>   
   
   ![image](https://user-images.githubusercontent.com/81348844/119148556-8fbfe000-ba87-11eb-8153-ee3cb9e5a03e.png)   
   실제로 푸딩 햄스터 test 이미지를 넣었더니 진짜 푸딩 햄스터로 판단해서 정말 신기했다.   
   
   
------ 
3. 'Advanced' 탐구
------
   
   ![image](https://user-images.githubusercontent.com/81348844/119148978-00ff9300-ba88-11eb-9562-7bb99d1c6f86.png)   
   일단 직접 탐구하기 전에 옆에 있는 ?(물음표) 를 클릭해서 설명들을 대충 읽어봤다.( 영어 극혐이지만 ㅜㅜㅜ )   
      
      
   대충 읽어보니 'Epochs' 는 데이터를 트레이닝 시키는 횟수인 것 같다. Epochs 가 높으면 높을수록 더 좋은 결과를 얻는다고 한다. (설명 왈...)   
   실제로 그럴까???  테스트를 시도했던 사진중에 펄 햄스터가 애매하게 결과가 나왔는데 Epochs를 50 > 80으로 올려 직접 시도해보았다.  
   ![image](https://user-images.githubusercontent.com/81348844/119149348-66538400-ba88-11eb-852f-ff9a6cfd9e08.png)   
   어... 결과가 더 안좋아진 것은 기분탓일 것이다. 내 모델은 아무런 잘못이 없다!! *^^*   
   눈물을 머금고 다른 테스트 사진을 넣어봤는데 그건 2%정도 정확성이 증가했다. ( 푸딩 햄스터 테스트 사진 )   
      
   나머지 기능들에 대해서도 탐구해봤는데   
   'Batch Size'는 모델을 트레이닝 시킬 때 이미지를 분류하는 집합(덩어리)의 크기? 같았다.   
   영어 설명읽기로는 부족해서 구글링으로 찾아봤더니 딥러닝 관련 언어였다...   
   어 일단 이정도로 알아두고 나중에 더 깊이 알아보는 걸로 결론 지었다... ㅎㅎ   
   
   'Learning Rate'는 학습률을 의미한다.   
   얘는 설명을 읽기위해 ?을 눌렀을 때 '조금만 건드려도 결과가 달라진다 조심해라 !' 라고 적혀있어서 의미심장한 것이었다.   
   실제로도 0.0005인가 증가시킨 뒤 모델을 트레이닝 시켰더니   
   원래 결과보다 결과가 정말 이상하게 나왔다.   그래서 조금만 건드려도 조심하라고 적혀있었던 것 같다.   
   
   ------ 
4. 5주차 미션 후기
------
    
    내 손으로 직접 이런 인공지능 모델을 만들어 본다는게 정말 신기했다. 처음 해보는 것이었기 때문이다.   
    꼰대는 아니지만 이렇게 방구석에서 나조차도 이런 인공지능 모델을 만들 수 있다니 세상이 참 좋아졌다고 느꼈다. ( 그게 바로 꼰대가 맞... 읍읍)   
    쨌든 너무나도 신기하고 재밌는 경험이었다.
       
    사실 가요 여러개 음악 파일로 있었다면 음원 듣고 무슨 노랜지 맞추기 뭐 이런 모델도 만들어보고 싶었는데   
    시간이 오래 걸릴 것 같아 포기했다.   다음 기회에...
   

   

